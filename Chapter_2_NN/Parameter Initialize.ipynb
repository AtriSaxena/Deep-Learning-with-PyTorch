{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization parameters \n",
    "\n",
    "Parameter initialization has a large impact on the model. Different initialization methods may lead to very different results. Fortunately, many pioneers of deep learning have helped us explore various initialization methods, so we only need to learn how to The assignment of the parameters of the model can be initialized.\n",
    "\n",
    "PyTorch's initialization method is not so obvious. If you create the model in the most primitive way, then you need to define all the parameters in the model. Of course, you can easily define how each variable is initialized, but for complex models, This is not easy, and we recommend using Sequential and Module to define the model, so this time we need to know how to customize the initialization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Numpy to Initialize\n",
    "\n",
    "Because PyTorch is a very flexible framework that can theoretically operate on all Tensor, so we can initialize it by defining a new Tensor, see the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Sequential Model\n",
    "net1 = nn.Sequential(\n",
    "    nn.Linear(30, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the parameters of the first layer\n",
    "w1 = net1[0].weight\n",
    "b1 = net1[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0893, -0.1465,  0.1232,  ...,  0.1127, -0.0025,  0.0747],\n",
      "        [ 0.0370,  0.0168,  0.0446,  ...,  0.1064,  0.1193,  0.1411],\n",
      "        [-0.0401,  0.0921,  0.0245,  ...,  0.0392, -0.1108,  0.1163],\n",
      "        ...,\n",
      "        [-0.0923,  0.0503,  0.1693,  ..., -0.1620, -0.1787,  0.1048],\n",
      "        [ 0.1787, -0.1095, -0.1695,  ...,  0.1630,  0.0420, -0.1173],\n",
      "        [ 0.0112, -0.0248, -0.0279,  ...,  0.0475,  0.1272, -0.1580]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a Parameter, which is a special Variable, we can access its .data properties to get the data there in, and then directly define a new Tensor replacing it, we can use PyTorch some random data generation methods, such as ```torch.randn``` If you want to use more randomization methods that are not available in PyTorch, you can use numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tensor to replace it directly\n",
    "net1[0].weight.data = torch.from_numpy(np.random.uniform(3, 5, size=(40, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[4.2730, 3.8316, 4.5334,  ..., 4.3201, 3.4712, 4.7432],\n",
      "        [3.0976, 3.1999, 3.2186,  ..., 3.9611, 3.5190, 4.3447],\n",
      "        [4.3775, 3.4772, 4.3067,  ..., 4.4263, 4.6262, 3.5110],\n",
      "        ...,\n",
      "        [4.8566, 4.6993, 3.2822,  ..., 3.3542, 3.3243, 4.9714],\n",
      "        [3.8446, 4.3848, 4.1489,  ..., 4.9076, 4.0676, 3.3540],\n",
      "        [4.6672, 4.7709, 4.7895,  ..., 3.9560, 3.8428, 4.5820]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net1[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the value of this parameter has been changed, that is, it has been defined as the initialization method we need. If a layer in the model needs us to modify it manually, then we can directly access it in this way, but More often than not, the same type of layer in the model needs to be initialized in the same way. A more efficient way to do this is to use a loop to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in net1:\n",
    "    if isinstance(layer, nn.Linear): # Determine wheather it is Linear Layer\n",
    "        param_shape = layer.weight.shape\n",
    "        layer.weight.data = torch.from_numpy(np.random.normal(0, 0.5, size=param_shape)) \n",
    "        # Define a normal distribution with mean of 0 and a variance of 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
